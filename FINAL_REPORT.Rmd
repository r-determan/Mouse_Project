---
title: "Final Report"
author: "Rose Determan, Shuting Li, Ranfei Xu"
date: 'May 12, 2022'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE,
                      message = FALSE)
knitr::opts_chunk$set(fig.width=6, fig.height=3,fig.align = "center") 
pacman::p_load(R.matlab, dplyr,tidyr, caret, factoextra, FactoMineR, pROC,stringr,cvms, keras,kerasR,permute)
```


```{r data prep}
# DATA SETUP
# Import mouse 409 data
bb <- readMat("Data/Zero_Maze/608034_409/Day_1/Trial_001_0/binned_behavior.mat")
bb <- data.frame(t(bb$binned.behavior))
names(bb) <- c("open", "closed")
bz <- readMat("Data/Zero_Maze/608034_409/Day_1/Trial_001_0/binned_zscore.mat")
bz <- data.frame(bz$binned.zscore)

#combine zscore and behavior
data <- data.frame(cbind(bb, bz))
  
#remove rows where no location is coded
data_clean <- data[-which(data$open==0 & data$closed==0),]
data_clean <- data_clean %>% select(-c(closed))
#select only "open" column as indicator
mdl_data <- data_clean 

#remove extra variables
rm(bb, bz, data)


# Import all mice data into one data frame
# read in our data
prefix <- "Data/Zero_Maze/"
folders <- list.files(prefix)

bz_all <- NULL
for (f in folders){
 #abbreviation for file name
 f_abbr <- str_sub(f, -3, -1)
 #subfolder
 sub_f <- list.files(paste0(prefix, f, "/Day_1/Trial_001_0"))
 
 # # MAKE EACH MOUSE IN ITS OWN VARIABLE
 # #binned behavior
 # assign(paste0("bb_",f_abbr), 
 #         readMat(paste0(prefix, f, "/Day_1/Trial_001_0/binned_behavior.mat")))
 # 
 # #z score
 # assign(paste0("bz_",f_abbr), 
 #         readMat(paste0(prefix, f, "/Day_1/Trial_001_0/binned_zscore.mat")))
  
 
 # ADD ALL MICE TO SAME VARIABLE
 #import data
  bb <- readMat(paste0(prefix, f, "/Day_1/Trial_001_0/binned_behavior.mat"))
  bz <- readMat(paste0(prefix, f, "/Day_1/Trial_001_0/binned_zscore.mat"))
 
 #extract dataframes from list
  bb <- t(bb$binned.behavior)
  bz <- data.frame(bz$binned.zscore)
 
 #add behavior to zscore dataframe
  bz$open <- bb[,2]
  bz$closed <- bb[,1]
 #add row number as time proxy
  bz$time <- seq(1:nrow(bz))

  #pivot long and add all data to a single dataframe
  bz_long <- bz %>% pivot_longer(cols = -c(open, closed, time)) %>% mutate(df = f_abbr)
  bz_all <- rbind(bz_all, bz_long)
}

#remove extra variables
rm(bz_long, f, f_abbr,folders, prefix, sub_f, bb, bz)

#select rows were location is coded and select only open column
bz_all <- bz_all[-which(bz_all$open==0 & bz_all$closed==0),]
bz_all <- bz_all %>% select(-closed)


all_results <- data.frame(model_name = NULL,
                          zero_rule_acc = NULL,
                          model_acc = NULL)
```

```{r functions}
plot_cm <- function(result, title = ""){
  cm <- confusion_matrix(targets =result$true, predictions = result$pred)
  plot_confusion_matrix(cm$`Confusion Matrix`[[1]],
                        add_sums = TRUE,
                        add_col_percentages = FALSE,
                        add_row_percentages = FALSE,
                        sums_settings = sum_tile_settings(
              palette = "Oranges",
              label = "Total",
              tc_tile_border_color = "black"
    )) + labs(title = title)
}

accuracy_table <- function(result, train_y, title = "",  all_results){
  # select whichever class is larger in the training data set
  # for testing, always predict the largest class from training set

  n_0 <- sum(train_y == 0)
  n_1 <- sum(train_y== 1)
  zero_rule_acc <- ifelse(n_0>n_1, 
                        sum(result$true == 0)/nrow(result),  
                        sum(result$true == 1)/nrow(result))
  all_results <- rbind(all_results, data.frame(model_name = title,
                                             zero_rule_acc = zero_rule_acc,
                                             model_acc = sum(result$true == result$pred)/nrow(result)))
  return(all_results)
}

n_lags <- 5
#create lag function
lagm <- function (x, k = 1) {
    n <- nrow (x)
    pad <- matrix (NA , k, ncol (x))
    rbind (pad , x[1:(n - k), ])
}

data_prep_lag <- function(data_clean, n_neurons, random_split = 0){
  #n_neurons <- ncol(data_clean)-1
  n_lags <- 5
  
  #data_mat <- data.matrix(data_clean %>% select(-closed))
  xdata <- data.matrix(data_clean %>% select(-c(open)) %>% select(seq(1,n_neurons)))
  ydata <- data.matrix(data_clean %>% select(open))

  #make lags
  arframe <- data.frame ( open = ydata ,
  L1 = lagm ( xdata , 1) , L2 = lagm ( xdata , 2),
  L3 = lagm ( xdata , 3) , L4 = lagm ( xdata , 4) ,
  L5 = lagm ( xdata , 5)
  )
  if (random_split == 0){
  #separate train and test
  istrain <- rep(TRUE, round(nrow(arframe)*0.7/2))
  istrain <- c(istrain, rep(FALSE,nrow(arframe)*0.3/2))
  istrain <- c(istrain,istrain)
  }
  else{
    istrain <- sample(c(TRUE,FALSE),size = nrow(arframe), prob = c(0.7,0.3), replace = TRUE)
  }
  
  #remove na rows due to lags
  arframe <- arframe [ -(1:n_lags) , ]
  istrain <- istrain [ -(1:n_lags) ]
  ydata <- ydata[-(1:n_lags)]
  n <- nrow ( arframe )
  #select only neuron data, including lags -- exclude "open"
  xrnn <- data.matrix ( arframe [ , -1])
  
  #dim(xrnn)
  xrnn <- array ( xrnn , c (n , n_neurons , n_lags) )  #format to n rows; number of neurons columns; number of lags layers
  #dim(xrnn)
  
  xrnn <- xrnn [ , , n_lags:1] #reorder columns 
  #aperm = Transpose an array by permuting its dimensions and optionally resizing it.
  #he final step rearranges the coordinates of the array (like a partial transpose) into the format that the RNN module in keras expects
  xrnn <- aperm ( xrnn , c (1 , 3 , 2) )
  #dim ( xrnn )
  
  out <- list(xrnn, arframe, istrain)
}

mcc <- function(y_true, y_pred){
  TP <- sum((y_true == 1)&(y_pred == 1))/1000
  FP <- sum((y_true == 0)&(y_pred == 1))/1000
  TN <- sum((y_true == 0)&(y_pred == 0))/1000
  FN <- sum((y_true == 1)&(y_pred == 0))/1000
  MCC <- ((TP*TN)-(FP*FN))/sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))
return(MCC)
}
```

# Introduction

Our group focus on the zero maze experiment which record the activation of neurons of each mice in the form of time series and the corresponding  location/behavior. Our goal is to apply different model to find the relationship between neuron activity pattern and behavior of mice.

We first focus on the mouse 409 with 25 neurons and extend to all neurons to find out the best predicted model by comparing confusion matrix for each model we tried. And then we apply the optimal model -  bidirectional LSTM to the data of all neurons of all mice to detect the stability of the model by comparing the accuracy of different mouse. In order to better display the predicted accuracy of bidirectional LSTM,  we also display the Zero Rule Accuracy and LSTM accuracy for all mice.

## Take Away Messages:

- **Training/Test Splitting Matter**: to ensure the sequence of the time series nature, we split the data set into chunks instead of randomly selected;
- **Zero Rule Accuracy**: to demonstrate the accuracy of each model, we introduce a baseline estimate which refers to zero rule accuracy. Specifically, we select the most common class in the training data set as our predicted value. Then our goal is to make the model accuracy higher than zero rule accuracy;
- Taking **all neurons** into consideration can improve the predicted accuracy;
- **Try different lags and Shuffle the behavior:** to explore the causal relationship between neuron activation and behaviors.


# Simple Model (Logistic Regression)

## Starting with Mouse 409

We chose logistic regression as our baseline model, considering its simple structure. Firstly, we applied logistic model into one mouse, No.409, to see the model performance.

Because mouse 409 has 110 neurons' recording, to decrease the dimension of our predictors (neurons), we used PCA to extract the main information of our raw data, and then we chose first 25 principle components as our predictors, to fit the logistic model.

Below is our model prediction result on the 30% testing data, setting 0.5 as the threshold of probability that staying closed arm or open arm. From the confusion matrix, we can see the proportion that predictions match real behaviors is around 71.7%.
```{r}
n_pc <- 25
mdl_data.pca <- PCA(mdl_data[,-1], scale.unit = TRUE, ncp=n_pc, graph = FALSE) #set graph=TRUE can see the arrow plot
eigenvalue <- get_eigenvalue(mdl_data.pca) #80:95.6%; 60:90%; 40: 80.8%


# extract principal components
comp <- data.frame(mdl_data.pca$ind$coord)

# fit model
comp$open <- mdl_data$open

train <- rep(TRUE, round(nrow(comp)*0.7/2))
train <- c(train, rep(FALSE,nrow(comp)*0.3/2))
train <- c(train,train)
training <- comp[train,]
testing <- comp[!train,]

mdl_logis <- glm(open~., data = training, family = binomial("logit"))
#summary(mdl_logis)

pred_logis <- predict(mdl_logis, newdata = testing, type = "response")
error_rate <- mean((pred_logis>.5 & testing$open == 0) | (pred_logis<.5 & testing$open == 1))
#error_rate

pred_logis <- ifelse(pred_logis>=0.5, 1, 0)


result <- data.frame(true = factor(testing$open),
                     pred = factor(pred_logis))
all_results <- accuracy_table(result, training$open,
                              title = "Logistic Reg w/ PCA (first 25 PCs)", 
                              all_results = all_results)
```

```{r, fig.cap = "Logistic regression confusion matrix for mouse 409. The accuracy of this model is 0.72 compared to the baseline accuracy of 0.75", warning=FALSE, fig.width=3, fig.height=3,fig.align = "center"}
plot_cm(result = result, title = "Logistic Reg w/ PCA (first 25 PCs)")
rm(comp, eigenvalue, mdl_data.pca, mdl_logis, training, testing, error_rate, pred_logis, train)
```


## All Mice

To explore the performance of logistic model on all mice, we applied logistic model into all mice data separately, with first 25 principle components of each mouse.

After we did prediction for all mice, we combined all results together, and calculated confusion matrix to see the average performance of logistic model. We can see the average accuracy of logistic is around 71.1%.

To identify the model performance difference between mice, we drew ROC curves for all mice, we can see logistic model performance good on mouse 274, but showed worse fitting on mouse 254, mouse 255 and some other mice. 

To see more clearly, we also drew the accuracy comparison plot for all mice. Zero Rule accuracy means the accuracy that we always chose the class has major proportion in our raw data, to compare them with model accuracy, we can easily identify logistic model performance on each mouse.
```{r, message=FALSE}
results <- data.frame(pred = NULL, true = NULL, mouse_id = NULL)
acc <- data.frame(mouse_id = NULL, prop_open = NULL, prop_closed = NULL, larger_class = NULL, accuracy = NULL)


for (id in unique(bz_all$df)){
  mdl_data <- bz_all %>% filter(df == id) %>% pivot_wider() %>% select(-c(df,time))
  #print(nrow(mdl_data))
  mdl_data.pca <- PCA(mdl_data[,-1], scale.unit = TRUE, ncp=n_pc, graph = FALSE) 
  eigenvalue <- get_eigenvalue(mdl_data.pca)
  
  # extract principal components
  comp <- data.frame(mdl_data.pca$ind$coord)
  
  # fit model
  comp$open <- mdl_data$open
  
  train <- rep(TRUE, round(nrow(comp)*0.7/2))
  train <- c(train, rep(FALSE,nrow(comp)*0.3/2))
  train <- c(train,train)
  training <- comp[train,]
  testing <- comp[!train,]

  mdl_logis <- glm(open~., data = training, family = binomial("logit"))
  pred_logis <- predict(mdl_logis, newdata = testing, type = "response")
  error_rate <- mean((pred_logis>.5 & testing$open == 0) | (pred_logis<.5 & testing$open == 1))
  #print(error_rate)

  logisROC <- roc(testing$open, pred_logis)
  assign(paste0("roc_",id),logisROC) 
  #---
  pred_logis <- ifelse(pred_logis>=0.5, 1, 0)
  
  results <- rbind(results, data.frame(pred = factor(pred_logis),true = factor(testing$open), mouse_id = id))
  acc <- rbind(acc, data.frame(mouse_id = id, 
                               prop_open = sum(mdl_data$open)/ nrow(mdl_data),
                               prop_closed = (nrow(mdl_data)-sum(mdl_data$open))/ nrow(mdl_data),
                               accuracy = 1-error_rate))


}

acc <- acc%>%  rowwise %>%mutate(larger_class =  max(prop_open, prop_closed))
```

```{r, fig.cap="Logistic regression confusion matrix for all mice models. The accuracy of this model is 0.71.", fig.width=3, fig.height=3,fig.align = "center", warning=FALSE}
# Across ALL models
cm <- confusion_matrix(predictions = results$pred, targets = results$true)

plot_confusion_matrix(cm$`Confusion Matrix`[[1]],
                      add_sums = TRUE,
                      add_col_percentages = FALSE,
                      add_row_percentages = FALSE,
                      sums_settings = sum_tile_settings(
            palette = "Oranges",
            label = "Total",
            tc_tile_border_color = "black"
  )) + labs(title = "Logistic Reg w/ PCA (all 11 mice/models)")

```

```{r, fig.cap = "Logistic ROC Curves for all mice"}
ggroc(list("251" = roc_251, "254" = roc_254,
           "255" = roc_255, "256" = roc_256,
           "274" = roc_274, "409" = roc_409,
           "412" = roc_412, "414" = roc_414,
           "416" = roc_416,
           "417" = roc_417, "418" = roc_418))
```

```{r,  fig.cap = "Logistic Accuracy Comparison plot for all mice"}
ggplot(data = acc,aes(x = mouse_id))+
  geom_errorbar(aes(ymax = accuracy, ymin = larger_class, x = mouse_id,y = accuracy),width = 0)+
  geom_point(aes(y = accuracy, color = "Model Accuracy"), size = 3)+
  geom_point(aes(y = larger_class, color = "Zero Rule Accuracy"), size = 3)+
  labs(x = "Mouse ID", y = "Accuracy", title = "Accuracy of Test Data for Each Mouse/Model", subtitle= "Where \"Zero Rule\" is always selecting the larger class \nGoal = Model Acc > Zero Rule Acc", color = "Accuracy")


rm(cm, comp, eigenvalue, logisROC, mdl_data, mdl_data.pca, mdl_logis, results,
   roc_251, roc_254, roc_255, roc_256,roc_257, roc_258, roc_274, roc_409, roc_412, roc_414, roc_416, roc_417, roc_418, 
   testing, training, error_rate, id, n_pc, pred_logis, train, acc)
```





# Neural Network Models

## Simple Neural Network Models: Mouse 409  

**Reason we try this model: Does the behavior impact neural activity? We assume the past location has influence on the current state of the neurons. **

To improve our prediction accuracy, we tried neural network on mouse 409, this model is more complex and precise than logistic model. Same with logistic, this model use current neuron activities to predict the current mouse location. But the difference is for this model we used all 110 neurons as predictors, because neural network has ability to process big data.

What's more, to identify the question about whether behavior impact neural activity, we explored the relationship between past locations with current neuron activities, the result showed that with 1 and 5 shift forward of location, the model accuracy can be improved a lot, so we assume the past location has influence on the current state of the neurons.

```{r,message=FALSE}
##mouse 409
#data_clean <- data_clean %>% mutate(open = as.numeric(open))

for (i in c(0,1,3,5)){
  behav <- c(rep(NA,i), data_clean$open[1:(length(data_clean$open)-i)])
  data_clean_behav <- cbind(behav, data_clean %>% select(-c(open))) %>% na.omit()
  istrain <- rep(TRUE, round(nrow(data_clean_behav)*0.7/2))
  istrain <- c(istrain, rep(FALSE,nrow(data_clean_behav)*0.3/2))
  istrain <- c(istrain,istrain)
    
  train <- data_clean_behav[istrain,]
  X_train <- train %>% select(-c(behav))
  X_train <- as.matrix(X_train)
  
  y_train <- train %>% select(behav)
  y_train <- as.matrix(y_train)
  
  test <-  data_clean_behav[!istrain,]
  X_test <- test %>% select(-c(behav))
  X_test <- as.matrix(X_test)
  y_test <- test %>% select(behav)
  y_test <- as.matrix(y_test)
  
  model <- keras_model_sequential() 
  
  # Add layers to the model
  model %>% 
      layer_dense(units = 100, activation = 'relu', input_shape = c(ncol(X_train))) %>% 
      layer_dense(units = 50, activation = 'relu') %>% 
      layer_dense(units = 1, activation = 'sigmoid')
  
  
  history <- model %>% 
    compile(
     loss = "binary_crossentropy",
     optimizer = optimizer_rmsprop(),
     metrics = c("accuracy"),
  )%>% 
    fit(X_train, y_train,
                epochs = 150, 
                batch_size = 50,
                validation_split = 0.3, verbose = 0)
  
  pred <- model %>% predict(X_test)
  pred <- ifelse(pred>=0.5, 1, 0)
  
  result <- data.frame(true = factor(y_test), pred = factor(pred))
  
  all_results <- accuracy_table(result,train_y = y_train,
                                title = paste0("Neural Net with ", i, " Level Shift of Outcome"), 
                                all_results = all_results)
}

rm(result, zero_rule_acc, model, pred, train, test, history, X_test, X_train, y_test,y_train, istrain)

all_results
```

## RNN with time lags : Mouse 409

The reason why we try this model is that simple neural network doesn't take into account about time series data. 

Since simple neural network model does not take into account about the order of sequence data, we tried RNN model, which is more helpful in modeling sequence data.

```{r, warning=FALSE, fig.cap="Right RNN confusion matrix for mouse 409.  The accuracy of this model is 0.724.",fig.width=3, fig.height=3,fig.align = "center"}
epochs = 150
n_neurons <- ncol(data_clean)-1 
out <- data_prep_lag(data_clean ,n_neurons )
xrnn <- out[[1]]
arframe <-  out[[2]]
n_lags <- 5
istrain <- out[[3]]
ydata <- arframe$open


model <- keras_model_sequential () %>%
  layer_simple_rnn ( units = 100 , 
                     input_shape = list (n_lags , n_neurons) ,
                     activation = "relu") %>%
  layer_dense ( units = 50, activation = "relu") %>% 
  layer_dense ( units = 1, activation = "sigmoid")
model %>% compile ( optimizer = optimizer_rmsprop() ,
                    loss = "binary_crossentropy",
                    metrics = c("accuracy") )
history <- model %>% 
  fit(xrnn[ istrain , , ] , arframe[ istrain , "open" ] ,
       batch_size = 50 , epochs = epochs ,
       validation_data = list ( xrnn [! istrain , , ] , arframe [! istrain , "open" ]), 
      verbose = 0
)
kpred <- predict ( model , xrnn [! istrain , , ])
y_true <- factor(matrix(ydata[!istrain]))
kpred <- factor(round(kpred,0))

result <- data.frame(true = y_true, pred = kpred)


plot_cm(result = result, title = "Correct RNN")
all_results <- accuracy_table(result,train_y = ydata[istrain],
                              title = "Correct RNN", 
                              all_results = all_results)

rm(arframe, xdata, epochs, istrain, model, n, n_lags, n_neurons, xrnn, y_true, ydata, zero_rule_acc, cm, history, result, kpred)
```
 
## LSTM and Bidirectional LSTM
We were interested in applying the LSTM (long short-term memory) model, since it addresses some of the shortcomings of the RNN structure. Simply, the LSTM model handles long term memory well. Additionally, the LSTM structure includes "gates" that allow the model to remember or forget information.   

We also considered a bidirectional LSTM, since it is unknown whether a neuron's activity impacts behavior or the behavior triggers neuron activity. A bidirectional model is one that is fit both forward (in the typical way that a sequential model is fit) and backward). We believe that is the bidirectional model has a higher accuracy than the traditional model, then there is preliminary evidence to suggest that the behavior impacts neuron activity. 

https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes/


```{r}
### here, we've commented out the model fits, and saved the results in a csv, since
### the models can take some time to fit. This way the document knits a bit faster


# epochs = 150
# n_lags <- 5
# all_mice_mdl<- NULL
# mcc_res <- NULL
# 
# for (mouse in unique(bz_all$df)){
#   result <- NULL
#   tStart <- Sys.time()
#   print(paste(mouse, "start"))
#   data <- bz_all %>% filter(df == mouse) %>% select(-c(df)) %>% pivot_wider() %>% select(-time)
#   n_neurons <- ncol(data)-1
# 
# 
#   out <- data_prep_lag(data ,n_neurons )
#   xrnn <- out[[1]]
#   arframe <-  out[[2]]
#   istrain <- out[[3]]
#   ydata <- arframe$open
# 
#   # BIDIRECTIONAL LSTM
#   model <- keras_model_sequential () %>%
#     bidirectional(layer_lstm(units = 50, input_shape = list(n_lags , n_neurons))) %>%
#     layer_dense ( units = 1, activation = "sigmoid")
#   model %>% compile ( optimizer = optimizer_rmsprop() ,
#                       loss = "binary_crossentropy",
#                       metrics = c("accuracy") )
#   history <- model %>%
#     fit(xrnn[ istrain , , ] , arframe[ istrain , "open" ] ,
#         batch_size = 50 , epochs = epochs ,
#         validation_data = list ( xrnn [! istrain , , ] , arframe [! istrain , "open" ]),
#         verbose = 0
#     )
#   kpred <- predict ( model , xrnn [! istrain , , ])
#   y_true <- factor(matrix(ydata[!istrain]))
#   kpred <- factor(round(kpred,0))
# 
# 
#   result <- data.frame(true = y_true, pred = kpred)
#   result$true <- factor(result$true, levels = c(0,1))
#   result$pred <- factor(result$pred, levels = c(0,1))
# 
#   all_mice_mdl <- accuracy_table(result, train_y = ydata[istrain],paste0("BILSTM_",mouse), all_mice_mdl)
#   mcc_res <- rbind(mcc_res, c(paste0("BILSTM_",mouse), mcc(result$true, result$pred)))
# 
# 
#   # REGULAR LSTM
#   model <- keras_model_sequential () %>%
#     layer_lstm(units = 50, input_shape = list(n_lags , n_neurons)) %>%
#     layer_dense ( units = 1, activation = "sigmoid")
#   model %>% compile ( optimizer = optimizer_rmsprop() ,
#                       loss = "binary_crossentropy",
#                       metrics = c("accuracy") )
#   history <- model %>%
#     fit(xrnn[ istrain , , ] , arframe[ istrain , "open" ] ,
#         batch_size = 50 , epochs = epochs ,
#         validation_data = list ( xrnn [! istrain , , ] , arframe [! istrain , "open" ]),
#         verbose = 0
#     )
#   kpred <- predict ( model , xrnn [! istrain , , ])
#   y_true <- factor(matrix(ydata[!istrain]))
#   kpred <- factor(round(kpred,0))
# 
# 
#   result <- data.frame(true = y_true, pred = kpred)
#   result$true <- factor(result$true, levels = c(0,1))
#   result$pred <- factor(result$pred, levels = c(0,1))
# 
#   all_mice_mdl <- accuracy_table(result, train_y = ydata[istrain],paste0("LSTM_",mouse), all_mice_mdl)
#   mcc_res <- rbind(mcc_res, c(paste0("LSTM_",mouse), mcc(result$true, result$pred)))
# 
# 
#   print(paste(mouse, "end.", Sys.time() - tStart))
# 
# 
# }
# res <- all_mice_mdl
# res <- res %>% mutate(mouse = str_extract(model_name, "\\d{3}"),
#                model = str_extract(model_name, "\\w{4,6}(?=_)")) %>%
#   select(-c(model_name)) %>%
#   pivot_wider(names_from = model, values_from = model_acc)
# 
# write.csv(res, "final_model_results.csv")
# write.csv(mcc_res, "final_model_results_mcc.csv")
```

```{r}
res <- read.csv("final_model_results.csv")
res$mouse <- as.factor(res$mouse)
res <- res %>% mutate(best_acc     = ifelse(zero_rule_acc>BILSTM & zero_rule_acc>LSTM, "Baseline", ifelse(BILSTM>LSTM, "BILSTM", "LSTM")),
                      best_acc_val = ifelse(zero_rule_acc>BILSTM & zero_rule_acc>LSTM, zero_rule_acc, ifelse(BILSTM>LSTM, BILSTM, LSTM)))



mcc_res <- read.csv("final_model_results_mcc.csv")
mcc_res <- mcc_res %>% mutate(mouse = str_extract(V1, "\\d{3}"),
               model = str_extract(V1, "\\w{4,6}(?=_)")) %>%
  select(-c(X, V1)) %>%
  pivot_wider(names_from = model, values_from = V2)
names(mcc_res) <- c("mouse", "mcc_BILSTM", "mcc_LSTM")
```

```{r fig.cap="This plot shows the accuracies of each of the three models. The baseline model shows the accuracy when we select the most common class from the training dataset. For 6 of the 13 mice, the baseline model has the highest accuracy, and for 6 mice the bidirectional LSTM model had the highest accuracy. In only one case, the LSTM model had the highest accuracy. "}
ggplot(data = res, aes(x =mouse))+
  geom_point(mapping = aes(y = zero_rule_acc, color = "Baseline"), size = 3)+
  geom_point(mapping = aes(y = BILSTM, color = "BI-LSTM"), size = 3)+
  geom_point(mapping = aes(y = LSTM, color = "LSTM"), size = 3)+
  labs(x = "Mouse", y = "Accuracy", colour = "Model", title = "Comparisons of Accuracies of Models")


res %>% select(c(mouse, best_acc, zero_rule_acc, LSTM, BILSTM)) %>% mutate(across(where(is.numeric),round,3)) %>% knitr::kable(col.names = c("Mouse", "Best Model", "Baseline", "LSTM", "Bi-LSTM"),caption = "Comparisons of accuracies of models")
```



# Conclusions
One of our main findings was the difference between randomly splitting the data set and "chunking" the training and testing data. When we randomly split the data into training and testing samples, the models have high testing accuracy, but we lose the sequence of the data. This is also allowing the model to learn from things that have already happened, and this might lead to an misleadingly high accuracy. The appendix shows the results of our incorrect model that led to this discovery. 

Another finding is the difference between the LSTM model and the Bidirectional LSTM Model. With the LSTM model, we are assuming that the neurons impact behavior, but with the Bidirectional LSTM Model we allow for the possibility that the behavior influences the neuron activity. In our results, we found that the Bidirectional LSTM model leads to higher prediction accuracy, and this may suggest that behavior influences the neuron activity. 


\newpage

# Appendix

## Incorrect Version w/ randomly selected train/test : Mouse 409
**At first, we incorrectly split the training and testing set randomly. The below shows the** ***incorrect*** **model. Interestingly, this incorrectly prepared model performs better than the RNN that is correctly setup.**

```{r}
n_lags <- 5
#create lag function
lagm <- function (x, k = 1) {
    n <- nrow (x)
    pad <- matrix (NA , k, ncol (x))
    rbind (pad , x[1:(n - k), ])
}

n_neurons <- 25
epochs = 150
out <- data_prep_lag(data_clean ,n_neurons , random_split = 1)
xrnn <- out[[1]]
arframe <-  out[[2]]
istrain <- out[[3]]
ydata <- arframe$open

model <- keras_model_sequential () %>%
  layer_simple_rnn ( units = 100 , 
                     input_shape = list (n_lags , n_neurons) ,
                     activation = "relu") %>%
  layer_dense ( units = 50, activation = "relu") %>% 
  layer_dense ( units = 1, activation = "sigmoid")
model %>% compile ( optimizer = optimizer_rmsprop() ,
                    loss = "binary_crossentropy",
                    metrics = c("accuracy") )
history <- model %>% 
  fit(xrnn[ istrain , , ] , arframe[ istrain , "open" ] ,
       batch_size = 50 , epochs = epochs ,
       validation_data = list ( xrnn [! istrain , , ] , arframe [! istrain , "open" ]), 
      verbose = 0
)
kpred <- predict ( model , xrnn [! istrain , , ])
y_true <- factor(matrix(ydata[!istrain]))
kpred <- factor(round(kpred,0))

summary(model)

plot(history)

result <- data.frame(true =y_true, pred = kpred)

plot_cm(result = result, title = "Incorrect RNN w/ 25 Neurons")
all_results <- accuracy_table(result,train_y = ydata[istrain],
                              title = "Incorrect RNN w/ 25 Neurons", 
                              all_results = all_results)

rm(arframe, xdata, epochs, istrain, model, n, n_neurons, xrnn, y_true, ydata, zero_rule_acc, cm, history, result, kpred)
```





